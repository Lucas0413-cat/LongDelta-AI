"""
LongDelta-AI Streamlit Frontend

Features:
- Streaming response from FastAPI backend
- Real-time message display with auto-scroll
- Interrupt handling for concurrent requests
- Chart rendering with None tolerance
"""
from __future__ import annotations

import json
import uuid

import requests
import streamlit as st

# Page config
st.set_page_config(
    page_title="LongDelta-AI ç»æµåˆ†æåŠ©æ‰‹",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# API endpoint - ä»ç¯å¢ƒå˜é‡è¯»å–
import os
API_BASE = os.environ.get("API_BASE", "http://localhost:8000")


def render_chart(chart_data: dict | None):
    """Render Plotly chart with None tolerance."""
    if not chart_data:
        return

    try:
        import plotly.express as px

        # None check
        if not isinstance(chart_data, dict):
            st.warning("å›¾è¡¨æ•°æ®ä¸ºç©º")
            return

        chart_type = chart_data.get("type")

        if chart_type == "bar":
            fig = px.bar(
                chart_data.get("data", []),
                x=chart_data.get("x", "x"),
                y=chart_data.get("y", "y"),
                title=chart_data.get("title", "")
            )
        elif chart_type == "pie":
            fig = px.pie(
                chart_data.get("data", []),
                names=chart_data.get("names", "names"),
                values=chart_data.get("values", "values"),
                title=chart_data.get("title", "")
            )
        elif chart_type == "line":
            fig = px.line(
                chart_data.get("data", []),
                x=chart_data.get("x", "x"),
                y=chart_data.get("y", "y"),
                title=chart_data.get("title", "")
            )
        else:
            st.warning(f"ä¸æ”¯æŒçš„å›¾è¡¨ç±»å‹: {chart_type}")
            return

        st.plotly_chart(fig, use_container_width=True)
    except Exception as e:
        st.error(f"å›¾è¡¨æ¸²æŸ“å¤±è´¥: {str(e)}")


def render_analysis_report(data: dict):
    """ç¾åŒ–çš„å•åœ°åŒºç»æµåˆ†ææŠ¥å‘Šæ¸²æŸ“"""
    if not isinstance(data, dict):
        return

    # æ•°æ®æ¦‚è§ˆ
    st.markdown("### ğŸ“Š åˆ†ææŠ¥å‘Š")

    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric(
            label=data.get("region", "") + " " + data.get("indicator", ""),
            value=f"{data.get('value_current', 0):,.2f}",
            delta=f"{data.get('growth_rate_percent', {}).get('value', 0)}%" if isinstance(data.get('growth_rate_percent'), dict) else str(data.get('growth_rate_percent', ''))
        )
    with col2:
        st.metric(
            label="ä¸ŠæœŸæ•°å€¼",
            value=f"{data.get('value_previous', 0):,.2f}",
            delta=data.get("unit", "")
        )
    with col3:
        st.metric(
            label="å¢é•¿è¶‹åŠ¿",
            value=data.get("growth_trend", ""),
            delta=str(data.get("year_current", "")) + " vs " + str(data.get("year_previous", ""))
        )

    st.markdown("---")

    # ç»¼åˆç»“è®º
    st.markdown("#### ğŸ“ ç»¼åˆç»“è®º")
    st.info(data.get("conclusion", ""))

    # å¢é•¿è¯¦æƒ…
    if isinstance(data.get("growth_rate_percent"), dict):
        gr = data["growth_rate_percent"]
        st.markdown(f"**å¢é•¿ç‡**: {gr.get('value', '')}{gr.get('unit', '')} ({gr.get('note', '')})")
    else:
        st.markdown(f"**å¢é•¿ç‡**: {data.get('growth_rate_percent', '')}")

    st.markdown("---")

    # çŸ­æ¿åˆ†æ
    if data.get("short_board_analysis"):
        st.markdown("#### âš ï¸ çŸ­æ¿åˆ†æä¸å»ºè®®")

        for i, item in enumerate(data["short_board_analysis"], 1):
            severity_emoji = {"è½»å¾®": "ğŸŸ¢", "ä¸­ç­‰": "ğŸŸ¡", "è¾ƒé«˜": "ğŸŸ ", "ä¸¥é‡": "ğŸ”´"}
            emoji = severity_emoji.get(item.get("severity", ""), "âšª")

            with st.expander(f"{emoji} çŸ­æ¿ {i}: {item.get('weakness', '')[:50]}..."):
                st.markdown(f"**ä¸¥é‡ç¨‹åº¦**: {item.get('severity', '')}")
                st.markdown(f"**çŸ­æ¿æè¿°**: {item.get('weakness', '')}")
                st.markdown(f"**æ”¹è¿›å»ºè®®**: {item.get('suggestion', '')}")

    # åŸå§‹æ•°æ®ï¼ˆå¯æŠ˜å ï¼‰
    with st.expander("ğŸ“„ åŸå§‹æ•°æ®"):
        st.json(data)


def render_multi_region_report(data: dict):
    """ç¾åŒ–çš„å¤šåœ°åŒºå¯¹æ¯”æŠ¥å‘Šæ¸²æŸ“"""
    if not isinstance(data, dict):
        return

    st.markdown("### ğŸ“Š å¤šåœ°åŒºå¯¹æ¯”åˆ†æ")

    regions = data.get("regions", [])
    indicator = data.get("indicator", "")
    year = data.get("year", "")

    # æ ‡é¢˜
    st.markdown(f"#### {indicator}å¯¹æ¯” ({year}å¹´)")
    st.markdown(f"**å¯¹æ¯”åœ°åŒº**: {', '.join(regions)}")

    st.markdown("---")

    # æ•°æ®æ±‡æ€»
    st.markdown("#### ğŸ“ˆ æ•°æ®æ±‡æ€»")
    st.info(data.get("data_summary", ""))

    # æ’åè¡¨æ ¼
    if data.get("ranking"):
        st.markdown("#### ğŸ† æ’å")
        ranking_data = data["ranking"]
        import pandas as pd
        df_ranking = pd.DataFrame(ranking_data)
        st.table(df_ranking)

        # ç»˜åˆ¶æ’åæŸ±çŠ¶å›¾
        import plotly.express as px

        # åŠ¨æ€è·å–åˆ—å
        df_ranking = pd.DataFrame(ranking_data)
        x_col = 'region' if 'region' in df_ranking.columns else ('area' if 'area' in df_ranking.columns else df_ranking.columns[0])

        fig = px.bar(
            df_ranking,
            x=x_col,
            y="value",
            title=f"{indicator}å¯¹æ¯” ({year})",
            labels={x_col: "åœ°åŒº", "value": indicator}
        )
        st.plotly_chart(fig, use_container_width=True)

    st.markdown("---")

    # å¯¹æ¯”åˆ†æ
    st.markdown("#### ğŸ” å¯¹æ¯”åˆ†æ")
    st.markdown(data.get("comparison_analysis", ""))

    st.markdown("---")

    # ç»¼åˆç»“è®º
    st.markdown("#### ğŸ“ ç»¼åˆç»“è®º")
    st.success(data.get("conclusion", ""))

    # åŸå§‹æ•°æ®ï¼ˆå¯æŠ˜å ï¼‰
    with st.expander("ğŸ“„ åŸå§‹æ•°æ®"):
        st.json(data)


def extract_json_from_content(content: str) -> str:
    """ä»å†…å®¹ä¸­æå– JSON å­—ç¬¦ä¸²ï¼ˆå¤„ç† Markdown ä»£ç å—ç­‰ï¼‰"""
    # ç§»é™¤ markdown ä»£ç å—æ ‡è®°
    content = content.strip()
    if content.startswith("```json"):
        content = content[7:]
        if content.endswith("```"):
            content = content[:-3]
    elif content.startswith("```"):
        content = content[3:]
        if content.endswith("```"):
            content = content[:-3]

    # æ‰¾åˆ° JSON å¯¹è±¡çš„å¼€å§‹å’Œç»“æŸ
    start = content.find('{"')
    if start == -1:
        start = content.find('{"')  # é‡æ–°æŸ¥æ‰¾
        if start == -1:
            return content.strip()

    # ç®€å•çš„æ‹¬å·åŒ¹é…æ¥æ‰¾åˆ°ç»“æŸä½ç½®
    brace_count = 0
    in_string = False
    for i, char in enumerate(content[start:], start):
        if char == '\\"' and in_string:
            continue
        if char == '"' and not in_string:
            in_string = True
        elif char == '"' and in_string:
            in_string = False
        if char == '{' and not in_string:
            brace_count += 1
        elif char == '}' and not in_string:
            brace_count -= 1
            if brace_count == 0:
                return content[start:i+1]

    return content.strip()


def is_multi_region_report(content: str) -> bool:
    """æ£€æµ‹å†…å®¹æ˜¯å¦ä¸ºå¤šåœ°åŒºå¯¹æ¯”æŠ¥å‘Š JSON"""
    # å°è¯•æå–å¹²å‡€çš„ JSON
    json_content = extract_json_from_content(content)

    try:
        data = json.loads(json_content)
        return (
            isinstance(data, dict) and
            "regions" in data and
            isinstance(data["regions"], list) and
            len(data["regions"]) > 1 and
            "comparison_analysis" in data
        )
    except (json.JSONDecodeError, TypeError, KeyError):
        return False


def is_analysis_report(content: str) -> bool:
    """æ£€æµ‹å†…å®¹æ˜¯å¦ä¸ºå•åœ°åŒºåˆ†ææŠ¥å‘Š JSON"""
    # å°è¯•æå–å¹²å‡€çš„ JSON
    json_content = extract_json_from_content(content)

    try:
        data = json.loads(json_content)
        return (
            isinstance(data, dict) and
            "region" in data and
            "indicator" in data and
            "conclusion" in data
        )
    except (json.JSONDecodeError, TypeError):
        return False


def parse_report_data(content: str) -> dict:
    """è§£ææŠ¥å‘Š JSON æ•°æ®"""
    # å°è¯•æå–å¹²å‡€çš„ JSON
    json_content = extract_json_from_content(content)

    try:
        return json.loads(json_content)
    except json.JSONDecodeError:
        return {}


def scroll_to_bottom():
    st.components.v1.html(
        """
        <script>
        setTimeout(function() {
            const el = document.getElementById("chat-bottom");
            if (el) el.scrollIntoView({behavior: "auto", block: "end", inline: "nearest"});
        }, 100);
        </script>
        """,
        height=0
    )


def init_session_state():
    """Initialize session state for interrupt handling."""
    if "request_id" not in st.session_state:
        st.session_state.request_id = None
    if "processing" not in st.session_state:
        st.session_state.processing = False
    if "pending_clear" not in st.session_state:
        st.session_state.pending_clear = False


def main():
    init_session_state()

    # Sidebar
    with st.sidebar:
        st.title("ğŸ“Š LongDelta-AI")
        st.markdown("### ç»æµæ•°æ®åˆ†æåŠ©æ‰‹")
        st.markdown("---")
        st.markdown("**ç¤ºä¾‹é—®é¢˜:**")
        examples = [
            "åˆ†æ2023å¹´å®‰å¾½GDP",
            "å¯¹æ¯”æ±Ÿæµ™æ²ªä¸‰äº§ç»“æ„",
            "æ±Ÿè‹2023å¹´CPIå¯¹æ¯”2022å¹´",
            "ä¸Šæµ·è¿‘5å¹´GDPå˜åŒ–è¶‹åŠ¿"
        ]
        for ex in examples:
            if st.button(ex, key=f"ex_{ex}"):
                st.session_state.question = ex

        st.markdown("---")
        st.markdown("**çŠ¶æ€:**")
        if st.button("æ£€æŸ¥åç«¯è¿æ¥"):
            try:
                resp = requests.get(f"{API_BASE}/health", timeout=5)
                if resp.status_code == 200:
                    st.success("åç«¯æœåŠ¡æ­£å¸¸")
                else:
                    st.warning("åç«¯æœåŠ¡å¼‚å¸¸")
            except Exception:
                st.error("æ— æ³•è¿æ¥åç«¯")

    # Main content
    st.title("ğŸ¢ é•¿ä¸‰è§’ç»æµåˆ†æåŠ©æ‰‹")
    st.markdown("è¾“å…¥æ‚¨çš„é—®é¢˜ï¼Œè·å–æ™ºèƒ½åˆ†ææŠ¥å‘Š")

    # Chat input
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # Auto-scroll to bottom on new message
    if st.session_state.processing:
        scroll_to_bottom()

    # Display chat history
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            if is_multi_region_report(msg["content"]):
                render_multi_region_report(parse_report_data(msg["content"]))
            elif is_analysis_report(msg["content"]):
                render_analysis_report(parse_report_data(msg["content"]))
            else:
                st.markdown(msg["content"])
            if msg.get("chart"):
                render_chart(msg["chart"])

    bottom_anchor = st.empty()
    bottom_anchor.markdown('<div id="chat-bottom"></div>', unsafe_allow_html=True)

    # Question input
    question = st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜...")

    if question:
        # Interrupt: cancel previous request by generating new request_id
        new_request_id = str(uuid.uuid4())
        st.session_state.request_id = new_request_id
        st.session_state.processing = True

        # Clear pending state
        st.session_state.pending_clear = True

        # Add user message
        st.session_state.messages.append({"role": "user", "content": question})
        with st.chat_message("user"):
            st.markdown(question)

        # Get streaming response
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            full_response = ""
            chart_data = None
            is_report = False
            cancelled = False
            try:
                response = requests.post(
                    f"{API_BASE}/chat/stream",
                    json={"question": question},
                    stream=True,
                    timeout=60
                )
                response.raise_for_status()

                for line in response.iter_lines():
                    if line:
                        # Interrupt check: if request_id changed, stop processing
                        if st.session_state.request_id != new_request_id:
                            cancelled = True
                            # 1) æ¸…ç©ºå½“å‰ assistant è¿™æ¡æ¶ˆæ¯çš„ä¸´æ—¶æ¸²æŸ“
                            message_placeholder.warning("â›” å·²ä¸­æ–­ä¸Šä¸€è½®è¾“å‡ºï¼Œå¼€å§‹å¤„ç†æ–°é—®é¢˜â€¦")
                            # 2) å…³é—­è¿æ¥ï¼Œé˜²æ­¢æ—§æµç»§ç»­å ç”¨
                            try:
                                response.close()
                            except Exception:
                                pass
                            # 3) æ ‡è®°å–æ¶ˆï¼Œé˜»æ­¢åç»­æ¸²æŸ“/ä¿å­˜
                            break

                        line_str = line.decode("utf-8")
                        if line_str.startswith("data: "):
                            try:
                                event = json.loads(line_str[6:])
                            except json.JSONDecodeError:
                                continue

                            event_type = event.get("type", event.get("event", ""))

                            if event_type == "thinking" or event_type == "tool_call":
                                msg_text = event.get("message", event.get("tool", ""))
                                message_placeholder.info(f"ğŸ¤” {msg_text}")
                                scroll_to_bottom()

                            elif event_type == "tool_result":
                                message_placeholder.success("âœ… å·¥å…·æ‰§è¡Œå®Œæˆ")
                                scroll_to_bottom()

                            elif event_type == "token":
                                chunk = event.get("chunk", "")
                                full_response += chunk
                                message_placeholder.markdown(full_response + "â–Œ")
                                scroll_to_bottom()

                            elif event_type == "final":
                                chunk = event.get("chunk", "")
                                full_response += chunk

                                # æ£€æµ‹æŠ¥å‘Šç±»å‹
                                if is_multi_region_report(full_response):
                                    is_report = True
                                    message_placeholder.empty()
                                    render_multi_region_report(parse_report_data(full_response))
                                    scroll_to_bottom()
                                elif is_analysis_report(full_response):
                                    is_report = True
                                    message_placeholder.empty()
                                    render_analysis_report(parse_report_data(full_response))
                                    scroll_to_bottom()
                                else:
                                    message_placeholder.markdown(full_response)
                                    scroll_to_bottom()

                                chart_data = event.get("chart") if isinstance(event.get("chart"), dict) else None
                                scroll_to_bottom()

                            elif event_type == "done":
                                if cancelled:
                                    break
                                if not is_report:
                                    message_placeholder.markdown(full_response)
                                    scroll_to_bottom()
                                if chart_data:
                                    render_chart(chart_data)
                                    scroll_to_bottom()
                                break

                            elif event_type == "error":
                                st.error(f"é”™è¯¯: {event.get('error', 'æœªçŸ¥é”™è¯¯')}")
                                scroll_to_bottom()
                                break

            except requests.exceptions.ConnectionError:
                st.error("æ— æ³•è¿æ¥åˆ°åç«¯æœåŠ¡ï¼Œè¯·ç¡®ä¿ FastAPI æœåŠ¡æ­£åœ¨è¿è¡Œ")
            except Exception as e:
                st.error(f"è¯·æ±‚é”™è¯¯: {str(e)}")

            # Save assistant response (only if not interrupted)
            if (not cancelled) and st.session_state.request_id == new_request_id:
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": full_response,
                    "chart": chart_data
                })

        # Reset processing flag
        st.session_state.processing = False

        # Auto-scroll to bottom after response
        scroll_to_bottom()


if __name__ == "__main__":
    main()
